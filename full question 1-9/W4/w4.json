[
    ["What is the primary goal of pattern recognition?", 
     "A. To change data formats", 
     "B. To identify patterns in data", 
     "C. To delete unwanted data", 
     "D. To secure data", 
     "", "B"],

    ["Which of the following is an example of supervised learning?", 
     "A. Clustering", 
     "B. Principal Component Analysis", 
     "C. K-nearest neighbors classification", 
     "D. Generating random data", 
     "", "C"],

    ["In which learning method are labels provided for all data points?", 
     "A. Unsupervised learning", 
     "B. Supervised learning", 
     "C. Semi-supervised learning", 
     "D. Reinforcement learning", 
     "", "B"],

    ["What is the key characteristic of linearly separable classes?", 
     "A. Classes are non-overlapping", 
     "B. Classes can be separated by a non-linear curve", 
     "C. Classes are random", 
     "D. Classes can be separated by a hyperplane", 
     "", "D"],

    ["Which algorithm maximizes the margin between classes?", 
     "A. K-means clustering", 
     "B. Support Vector Machines", 
     "C. Decision trees", 
     "D. Linear regression", 
     "", "B"],

    ["What is the main purpose of feature extraction?", 
     "A. To compress data", 
     "B. To identify important data attributes", 
     "C. To increase data size", 
     "D. To store data", 
     "", "B"],

    ["Which classifier uses a hyperplane for classification?", 
     "A. K-nearest neighbors", 
     "B. Decision trees", 
     "C. Support Vector Machines", 
     "D. Random forests", 
     "", "C"],

    ["What does a confusion matrix measure?", 
     "A. Number of features", 
     "B. Classification errors", 
     "C. Data size", 
     "D. Feature relevance", 
     "", "B"],

    ["What is the main advantage of ensemble learning methods?", 
     "A. Faster computation", 
     "B. Better generalization and accuracy", 
     "C. Reduced data storage", 
     "D. Simplified algorithms", 
     "", "B"],

    ["Which metric is used to evaluate regression models?", 
     "A. Accuracy", 
     "B. Confusion matrix", 
     "C. Root Mean Square Error (RMSE)", 
     "D. True Positive Rate", 
     "", "C"],

    ["In regression analysis, what does 'R-squared' represent?", 
     "A. Error rate", 
     "B. Variance explained by the model", 
     "C. Data transformation rate", 
     "D. Prediction speed", 
     "", "B"],

    ["Which method uses multiple classifiers for multiclass classification?", 
     "A. One vs. all", 
     "B. All vs. one", 
     "C. Linear regression", 
     "D. Single classifier", 
     "", "A"],

    ["What is the function of kernel functions in SVM?", 
     "A. Simplify data storage", 
     "B. Map features into higher-dimensional space", 
     "C. Reduce computation time", 
     "D. Compress data", 
     "", "B"],

    ["What does ROC curve stand for?", 
     "A. Random Operating Curve", 
     "B. Receiver Operating Characteristic", 
     "C. Regular Operating Class", 
     "D. Recurrent Operating Chart", 
     "", "B"],

    ["What is the main purpose of cross-validation?", 
     "A. Increase model complexity", 
     "B. Assess model performance on new data", 
     "C. Reduce dataset size", 
     "D. Simplify algorithm", 
     "", "B"],

    ["Which method is commonly used for binary classification?", 
     "A. Random forests", 
     "B. Decision trees", 
     "C. Support Vector Machines", 
     "D. Clustering", 
     "", "C"],

    ["What is the role of 'slack variables' in soft-margin SVMs?", 
     "A. Improve data compression", 
     "B. Allow misclassification of data", 
     "C. Reduce computation cost", 
     "D. Increase margin", 
     "", "B"],

    ["What does precision measure in classification?", 
     "A. Total error rate", 
     "B. Proportion of true positives among all positive predictions", 
     "C. Proportion of true negatives among all negative predictions", 
     "D. Total prediction time", 
     "", "B"],

    ["What is the F1 score?", 
     "A. Average of precision and recall", 
     "B. Harmonic mean of precision and recall", 
     "C. Sum of precision and recall", 
     "D. Difference between precision and recall", 
     "", "B"],

    ["Which technique is used to handle noisy data in SVM?", 
     "A. Kernel trick", 
     "B. Hard margin", 
     "C. Soft margin with slack variables", 
     "D. Feature extraction", 
     "", "C"],

    ["What is a key advantage of decision trees?", 
     "A. High accuracy in high-dimensional data", 
     "B. Easy to interpret and visualize", 
     "C. Fast training on large datasets", 
     "D. Minimal memory usage", 
     "", "B"],

    ["Which classifier calculates the mean of each class for classification?", 
     "A. Nearest class mean classifier", 
     "B. K-nearest neighbors", 
     "C. Decision tree", 
     "D. Random forest", 
     "", "A"],

    ["What does the term 'hyperplane' refer to in SVM?", 
     "A. Data storage format", 
     "B. Decision boundary that separates classes", 
     "C. Algorithm complexity", 
     "D. Feature extraction technique", 
     "", "B"],

    ["Which method splits data into k subsets for validation?", 
     "A. Train-test split", 
     "B. K-fold cross-validation", 
     "C. Random sampling", 
     "D. Sequential partitioning", 
     "", "B"],

    ["What is the main challenge of using SVM with large datasets?", 
     "A. Complexity in hyperparameter tuning", 
     "B. Inefficiency in training time", 
     "C. Inaccuracy in low-dimensional data", 
     "D. Lack of interpretability", 
     "", "B"],

    ["Which method improves model performance by combining multiple models?", 
     "A. Stochastic gradient descent", 
     "B. Bagging", 
     "C. Ensemble learning", 
     "D. Singular value decomposition", 
     "", "C"],

    ["What does a large margin indicate in SVM?", 
     "A. Better generalization", 
     "B. Higher accuracy", 
     "C. Increased complexity", 
     "D. Reduced dataset size", 
     "", "A"],

    ["What is the purpose of using kernel functions in nonlinear SVM?", 
     "A. Reduce dataset size", 
     "B. Avoid overfitting", 
     "C. Transform data into higher dimensions", 
     "D. Simplify model structure", 
     "", "C"],

    ["What is the primary benefit of using random forests?", 
     "A. Speed in computation", 
     "B. Interpretability", 
     "C. Robustness against overfitting", 
     "D. Data compression", 
     "", "C"],

    ["What does MAE stand for in regression evaluation?", 
     "A. Mean Absolute Error", 
     "B. Maximum Accuracy Estimate", 
     "C. Mean Aggregate Error", 
     "D. Model Accuracy Evaluation", 
     "", "A"],

    ["Which of the following is a type of ensemble learning?", 
     "A. Decision trees", 
     "B. Random forests", 
     "C. Linear regression", 
     "D. Support vector machines", 
     "", "B"],

    ["In classification, what is a false positive?", 
     "A. Correct classification of a positive instance", 
     "B. Incorrect classification of a negative instance as positive", 
     "C. Correct classification of a negative instance", 
     "D. Incorrect classification of a positive instance as negative", 
     "", "B"],

    ["What is an advantage of using k-nearest neighbors?", 
     "A. Fast computation", 
     "B. Simple and intuitive", 
     "C. High interpretability", 
     "D. Data compression", 
     "", "B"],

    ["Which algorithm is sensitive to the curse of dimensionality?", 
     "A. Support vector machines", 
     "B. K-nearest neighbors", 
     "C. Decision trees", 
     "D. Random forests", 
     "", "B"],

    ["What does 'overfitting' mean in model training?", 
     "A. Model fits training data too closely, performing poorly on new data", 
     "B. Model generalizes well to new data", 
     "C. Model trains quickly with minimal data", 
     "D. Model uses all available features", 
     "", "A"],

    ["Which type of error is a Type II error?", 
     "A. False positive", 
     "B. True positive", 
     "C. False negative", 
     "D. True negative", 
     "", "C"],

    ["What is the main advantage of linear classifiers?", 
     "A. Handles complex decision boundaries", 
     "B. Simplicity and ease of interpretation", 
     "C. Robust against noise", 
     "D. High computational cost", 
     "", "B"],

    ["In decision trees, what does a leaf node represent?", 
     "A. Feature selection", 
     "B. Decision boundary", 
     "C. Class label", 
     "D. Data split", 
     "", "C"],

    ["Which of the following is not a regression evaluation metric?", 
     "A. RMSE", 
     "B. MAE", 
     "C. AUC", 
     "D. R-squared", 
     "", "C"],

    ["What does 'regularization' aim to prevent in model training?", 
     "A. Data loss", 
     "B. Overfitting", 
     "C. Underfitting", 
     "D. Overfitting and underfitting", 
     "", "B"],

    ["Which model is used to estimate probabilities of different classes?", 
     "A. Decision trees", 
     "B. Bayesian decision theory", 
     "C. Support vector machines", 
     "D. Linear regression", 
     "", "B"],

    ["What is the role of decision rules in SVM testing?", 
     "A. Simplify data storage", 
     "B. Determine class membership", 
     "C. Optimize feature selection", 
     "D. Reduce training time", 
     "", "B"],

    ["Which term describes an error in rejecting a true null hypothesis?", 
     "A. Type I error", 
     "B. Type II error", 
     "C. True negative", 
     "D. True positive", 
     "", "A"],

    ["What is the primary goal of regression analysis?", 
     "A. Classify data", 
     "B. Predict continuous outcomes", 
     "C. Reduce dimensionality", 
     "D. Detect anomalies", 
     "", "B"],

    ["In cross-validation, what does the 'train-test split' technique involve?", 
     "A. Splitting data into features and labels", 
     "B. Dividing data into training and testing sets", 
     "C. Splitting data into high and low values", 
     "D. Separating data based on class labels", 
     "", "B"],

    ["What is a primary disadvantage of decision trees?", 
     "A. High accuracy in large datasets", 
     "B. Tendency to overfit", 
     "C. Simple visualization", 
     "D. Fast computation", 
     "", "B"],

    ["What is the purpose of feature selection in pattern recognition?", 
     "A. Increase data size", 
     "B. Select the most relevant features", 
     "C. Remove noise from data", 
     "D. Simplify data structure", 
     "", "B"],

    ["Which concept refers to the ability of a model to perform well on unseen data?", 
     "A. Overfitting", 
     "B. Underfitting", 
     "C. Generalization", 
     "D. Regularization", 
     "", "C"],

    ["What is the role of a 'decision boundary' in classification?", 
     "A. Separate classes in feature space", 
     "B. Enhance data visualization", 
     "C. Simplify computation", 
     "D. Store data efficiently", 
     "", "A"],

    ["What does a high AUC value indicate in ROC analysis?", 
     "A. Low classification performance", 
     "B. High classification performance", 
     "C. Balanced error rate", 
     "D. Inconsistent results", 
     "", "B"]
]
